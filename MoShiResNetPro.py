# =====================================
# ä¹¦æ³•å­—ä½“åˆ†ç±» - å¢å¼ºç‰ˆ "å¢¨è¯† MoShi"ï¼ˆå…¨æ¨¡å‹å¾®è°ƒç‰ˆï¼‰
# =====================================
import time
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, ConcatDataset, random_split
from PIL import UnidentifiedImageError
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# --------------------------
# 1ï¸âƒ£ åŸºæœ¬å‚æ•°
# --------------------------
data_dirs = ['KaggleImages', 'SupplementaryImages']
batch_size = 32
num_epochs = 25
learning_rate = 1e-5  # âœ… å…¨æ¨¡å‹å¾®è°ƒå»ºè®®æ›´å°å­¦ä¹ ç‡
val_ratio = 0.2
num_workers = 4
MODEL_NAME = 'efficientnet_b0'  # 'resnet18' æˆ– 'efficientnet_b0'

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --------------------------
# 2ï¸âƒ£ æ•°æ®å¢å¼ºä¸é¢„å¤„ç†
# --------------------------
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.RandomRotation(15),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.RandomHorizontalFlip(p=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# --------------------------
# âœ… å®‰å…¨ç‰ˆ ImageFolder
# --------------------------
class SafeImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        path, target = self.samples[index]
        try:
            sample = self.loader(path)
        except (OSError, UnidentifiedImageError):
            print(f"[è­¦å‘Š] è·³è¿‡æŸåå›¾ç‰‡: {path}")
            return None
        if self.transform:
            sample = self.transform(sample)
        return sample, target

# --------------------------
# âœ… è‡ªå®šä¹‰ collate_fn
# --------------------------
def safe_collate_fn(batch):
    batch = [b for b in batch if b is not None]
    if len(batch) == 0:
        return None
    return torch.utils.data.dataloader.default_collate(batch)

# --------------------------
# ğŸ”¹ ä¸»è¿è¡ŒåŒº
# --------------------------
if __name__ == "__main__":
    print("Using device:", device)

    # --------------------------
    # ğŸŒ± å›ºå®šéšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°æ€§ï¼‰
    # --------------------------
    seed = 42
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    # --------------------------
    # 3ï¸âƒ£ åŠ è½½å¤šä¸ªæ•°æ®æºå¹¶åˆå¹¶
    # --------------------------
    datasets_list = []
    for d in data_dirs:
        ds = SafeImageFolder(d, transform=train_transforms)
        datasets_list.append(ds)

    full_dataset = ConcatDataset(datasets_list)
    num_classes = len(datasets_list[0].classes)
    print(f"Classes: {datasets_list[0].classes}")

    # --------------------------
    # 4ï¸âƒ£ åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    # --------------------------
    val_size = int(len(full_dataset) * val_ratio)
    train_size = len(full_dataset) - val_size
    train_dataset, val_dataset = random_split(
        full_dataset,
        [train_size, val_size],
        generator=torch.Generator().manual_seed(seed)
    )

    val_dataset.dataset.transform = val_transforms

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                              num_workers=num_workers, pin_memory=True,
                              collate_fn=safe_collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                            num_workers=num_workers, pin_memory=True,
                            collate_fn=safe_collate_fn)

    print(f"ğŸ“Š Total: {len(full_dataset)} images | Train: {train_size} | Val: {val_size}")

    # --------------------------
    # 5ï¸âƒ£ æ¨¡å‹é€‰æ‹©ï¼ˆå…¨æ¨¡å‹å¾®è°ƒï¼‰
    # --------------------------
    if MODEL_NAME == 'resnet18':
        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, num_classes)

        # âœ… è§£å†»æ‰€æœ‰å‚æ•°
        for param in model.parameters():
            param.requires_grad = True

        print("âœ… ä½¿ç”¨ ResNet18ï¼ˆå…¨æ¨¡å‹å¾®è°ƒï¼‰")

    elif MODEL_NAME == 'efficientnet_b0':
        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, num_classes)

        # âœ… è§£å†»æ‰€æœ‰å‚æ•°
        for param in model.parameters():
            param.requires_grad = True

        print("âœ… ä½¿ç”¨ EfficientNet_B0ï¼ˆå…¨æ¨¡å‹å¾®è°ƒï¼‰")

    else:
        raise ValueError("Unsupported MODEL_NAME")

    model = model.to(device)

    # --------------------------
    # 6ï¸âƒ£ æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    # --------------------------
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“Š æ€»å‚æ•°é‡: {total_params:,}")
    print(f"ğŸŸ¢ å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,} ({trainable_params / total_params * 100:.2f}%)")
    print(f"âœ… Using model: {MODEL_NAME}")

    # --------------------------
    # 7ï¸âƒ£ è®­ç»ƒå¾ªç¯
    # --------------------------
    train_acc_list, val_acc_list = [], []
    print("ğŸš€ å¼€å§‹è®­ç»ƒå¾ªç¯...")

    for epoch in range(num_epochs):
        model.train()
        train_loss, train_correct, train_total = 0, 0, 0
        start_time = time.time()

        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", ncols=100)
        for batch in pbar:
            if batch is None:
                continue
            images, labels = batch
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * images.size(0)
            train_correct += (outputs.argmax(1) == labels).sum().item()
            train_total += labels.size(0)
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})

        epoch_time = time.time() - start_time
        train_acc = train_correct / train_total if train_total > 0 else 0.0
        train_acc_list.append(train_acc)

        # --------------------------
        # éªŒè¯é˜¶æ®µ
        # --------------------------
        model.eval()
        val_correct, val_total = 0, 0
        all_preds, all_labels = [], []

        with torch.no_grad():
            for batch in val_loader:
                if batch is None:
                    continue
                images, labels = batch
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                preds = outputs.argmax(1)
                val_correct += (preds == labels).sum().item()
                val_total += labels.size(0)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        val_acc = val_correct / val_total if val_total > 0 else 0.0
        val_acc_list.append(val_acc)

        print(f"\nğŸ§¾ Epoch [{epoch+1}/{num_epochs}] å®Œæˆ | "
              f"ğŸ•’ {epoch_time:.1f}s | âœ… Train Acc: {train_acc:.3f} | ğŸ§ª Val Acc: {val_acc:.3f}")
        if torch.cuda.is_available():
            print(f"ğŸ’¾ GPU æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")

    # --------------------------
    # 8ï¸âƒ£ æ··æ·†çŸ©é˜µå¯è§†åŒ–
    # --------------------------
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=datasets_list[0].classes,
                yticklabels=datasets_list[0].classes)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(f'Confusion Matrix - {MODEL_NAME.upper()} (MoShi)')
    plt.show()

    # --------------------------
    # 9ï¸âƒ£ è®­ç»ƒæ›²çº¿
    # --------------------------
    plt.figure(figsize=(8,4))
    plt.plot(train_acc_list, label='Train Acc')
    plt.plot(val_acc_list, label='Val Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title(f'Training Curve - {MODEL_NAME.upper()} (MoShi)')
    plt.show()

    # --------------------------
    # ğŸ”Ÿ ä¿å­˜æ¨¡å‹
    # --------------------------
    torch.save(model.state_dict(), f'ModelCheckpoints/MoShi_{MODEL_NAME}_trained_all_params.pth')
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º MoShi_{MODEL_NAME}_trained_all_params.pth")
